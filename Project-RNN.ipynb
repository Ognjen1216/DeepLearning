{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Project-RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "k-k1u4GyD9G_",
        "colab_type": "code",
        "outputId": "10a8b0ae-8f70-47b1-ee3b-81cdfb044da1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torchvision\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import Linear, RNN, LSTM\n",
        "from torch.nn.functional import softmax, relu, nll_loss, log_softmax\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "import h5py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 4.3MB/s \n",
            "\u001b[?25hCollecting torch (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 32kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x590e4000 @  0x7fe1412662a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 5.3MB/s \n",
            "\u001b[?25hInstalling collected packages: torch, pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0 torch-0.4.1 torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VFZsg0NGEChC",
        "colab_type": "code",
        "outputId": "92e03102-b6f9-4494-8d1c-67b84676567e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HXvQdA6CD9HH",
        "colab_type": "code",
        "outputId": "409dfa6f-e311-439e-89ed-4eb7fc757844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "print(use_cuda)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8-0RgCyWD9HP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "with h5py.File('/content/drive/My Drive/Colab Notebooks/L4M_dataset.hdf5', 'r') as hf:\n",
        "    data = hf['data'][:]\n",
        "    label = hf['label'][:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K3QDYE4LD9HU",
        "colab_type": "code",
        "outputId": "95f2471c-7004-4c77-97e7-412045615e2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "print(np.max(data[:,1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H1NyI4ZAD9Hb",
        "colab_type": "code",
        "outputId": "a55faf88-0a13-4a7d-cbd9-45feda2fadd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "seq = [] #Initalize\n",
        "lab = []\n",
        "current_user = -1\n",
        "for i in range(data.shape[0]): # going through the data and sorting into user sequences\n",
        "    if data[i,0]!=current_user:\n",
        "        current_user = data[i,0]\n",
        "        seq.append([data[i,1]])\n",
        "        lab.append([label[i]])        \n",
        "    else:\n",
        "        seq[-1].append(data[i,1]) # new user line\n",
        "        lab[-1].append(label[i])\n",
        "        \n",
        "train_idx = np.random.choice(len(seq),(len(seq)*8)//10,replace = False)\n",
        "seq_train = [seq[i] for i in train_idx]\n",
        "seq_test = [seq[i] for i in range(len(seq)) if i not in train_idx]\n",
        "lab_train = [lab[i] for i in train_idx]\n",
        "lab_test = [lab[i] for i in range(len(lab)) if i not in train_idx]\n",
        "\n",
        "seq_train.sort(key=lambda x:len(x))\n",
        "lab_train.sort(key=lambda x:len(x))\n",
        "seq_test.sort(key=lambda x:len(x))\n",
        "lab_test.sort(key=lambda x:len(x))\n",
        "seq_train = [item for item in seq_train if len(item) > 19]\n",
        "lab_train = [item for item in lab_train if len(item) > 19]\n",
        "seq_test = [item for item in seq_test if len(item) > 19]\n",
        "lab_test = [item for item in lab_test if len(item) > 19]\n",
        "seq_length_train = [len(x) for x in seq_train]\n",
        "seq_length_test = [len(x) for x in seq_test]\n",
        "\n",
        "print(len(seq_train))\n",
        "print(len(seq_test))\n",
        "print(len(lab_train))\n",
        "print(len(lab_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120445\n",
            "30071\n",
            "120445\n",
            "30071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hd04CyW1D9Hf",
        "colab_type": "code",
        "outputId": "3d976e34-eb59-46a0-c70a-b11fbc2acde7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "cell_type": "code",
      "source": [
        "# Define network\n",
        "output_size = 17770\n",
        "num_input = 17770\n",
        "hidden_size_rnn1 = 1000\n",
        "hidden_size_lin1 = 1000\n",
        "\n",
        "hidden_size_rnn2 = 5000\n",
        "hidden_size_lin2 = 5000\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.one_hot = nn.Embedding(num_input, num_input)\n",
        "        self.one_hot.weight.data = torch.eye(num_input)\n",
        "        self.one_hot.weight.detach_()\n",
        "        \n",
        "        self.rnn1 = LSTM(input_size=num_input,\n",
        "                        hidden_size=hidden_size_rnn1,\n",
        "                        num_layers=1,\n",
        "                        bidirectional=False,\n",
        "                        batch_first = True)\n",
        "        \n",
        "        self.lin1 = Linear(in_features=hidden_size_rnn1,\n",
        "                           out_features=hidden_size_lin1,\n",
        "                           bias=False)\n",
        "        \n",
        "        #self.rnn2 = LSTM(input_size=hidden_size_lin1,\n",
        "        #                 hidden_size=hidden_size_rnn2,\n",
        "        #                 num_layers=1,\n",
        "        #                 bidirectional=False,\n",
        "        #                 batch_first=True)\n",
        "        \n",
        "        #self.lin2 = Linear(in_features=hidden_size_rnn2,\n",
        "        #                   out_features=hidden_size_lin2,\n",
        "        #                   bias=False)\n",
        "        \n",
        "        self.l_out = Linear(in_features=hidden_size_lin1,\n",
        "                            out_features=output_size,\n",
        "                            bias=False)\n",
        "        \n",
        "        self.criteria = nn.CrossEntropyLoss()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = {}\n",
        "        x = self.one_hot(x)\n",
        "        \n",
        "        x, hn = self.rnn1(x)\n",
        "        \n",
        "        x = relu(self.lin1(x))\n",
        "        \n",
        "        \n",
        "        #x, hn = self.rnn2(x)\n",
        "        \n",
        "        #x = relu(self.lin2(x))\n",
        "        \n",
        "        out = self.l_out(x)\n",
        "        return out\n",
        "    \n",
        "net = Net()\n",
        "if use_cuda:\n",
        "    print('##converting network to cuda-enabled')\n",
        "    net.cuda()\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##converting network to cuda-enabled\n",
            "Net(\n",
            "  (one_hot): Embedding(17770, 17770)\n",
            "  (rnn1): LSTM(17770, 1000, batch_first=True)\n",
            "  (lin1): Linear(in_features=1000, out_features=1000, bias=False)\n",
            "  (l_out): Linear(in_features=1000, out_features=17770, bias=False)\n",
            "  (criteria): CrossEntropyLoss()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eetzO83QD9Hl",
        "colab_type": "code",
        "outputId": "f60e4e7d-0df7-4959-9def-e7d60271c6e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "cell_type": "code",
      "source": [
        "{p[0]: p[1].requires_grad for p in net.named_parameters()}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'l_out.weight': True,\n",
              " 'lin1.weight': True,\n",
              " 'one_hot.weight': False,\n",
              " 'rnn1.bias_hh_l0': True,\n",
              " 'rnn1.bias_ih_l0': True,\n",
              " 'rnn1.weight_hh_l0': True,\n",
              " 'rnn1.weight_ih_l0': True}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "KLoyUlXbD9Hq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(net.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dsbuay77D9Hu",
        "colab_type": "code",
        "outputId": "436aa576-81c0-4820-a261-38136f2a2188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1850
        }
      },
      "cell_type": "code",
      "source": [
        "# Train and validation loop\n",
        "batch_size = 50\n",
        "net.train()\n",
        "counter = 0\n",
        "temp = 0\n",
        "for i in np.random.choice(len(seq_train)//batch_size,len(seq_train)//batch_size, replace=False):\n",
        "    batch = seq_train[i*batch_size:(i+1)*batch_size]\n",
        "    batch_length = seq_length_train[i*batch_size:(i+1)*batch_size]\n",
        "    batch_label = lab_train[i*batch_size:(i+1)*batch_size]\n",
        "    \n",
        "    # Cutting\n",
        "    min_len_batch = min(batch_length)\n",
        "    #batch_cut = np.zeros((batch_size,min_len_batch))\n",
        "    #label_cut = np.zeros((batch_size,min_len_batch))\n",
        "    #for j in range(batch_size):\n",
        "    batch = np.array([item[:min_len_batch] for item in batch]) \n",
        "    batch_label = np.array([item[:min_len_batch] for item in batch_label])\n",
        "    batch = torch.from_numpy(batch).long()\n",
        "    batch_label = torch.from_numpy(batch_label).long()\n",
        "    if use_cuda:\n",
        "        batch = Variable(batch.cuda())\n",
        "        batch_label = Variable(batch_label.cuda())\n",
        "    output = net(batch)\n",
        "    #print(\"MAX\",output.max())\n",
        "    #print('batch_length:',batch_length)\n",
        "    batch_loss = net.criteria(output.view(-1,output_size),batch_label.view(-1))\n",
        "    temp = temp + batch_loss\n",
        "    if counter%50==0:\n",
        "      print('Train completed:',counter)\n",
        "      print('Loss'+' '+str(counter)+':',temp/50)\n",
        "      temp = 0\n",
        "    counter += 1\n",
        "    optimizer.zero_grad()\n",
        "    batch_loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train completed: 0\n",
            "Loss 0: tensor(0.1957, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 50\n",
            "Loss 50: tensor(8.9428, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 100\n",
            "Loss 100: tensor(7.9159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 150\n",
            "Loss 150: tensor(7.8275, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 200\n",
            "Loss 200: tensor(7.5522, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 250\n",
            "Loss 250: tensor(7.3570, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 300\n",
            "Loss 300: tensor(7.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 350\n",
            "Loss 350: tensor(6.9800, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 400\n",
            "Loss 400: tensor(6.7727, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 450\n",
            "Loss 450: tensor(6.6104, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 500\n",
            "Loss 500: tensor(6.5469, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 550\n",
            "Loss 550: tensor(6.4567, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 600\n",
            "Loss 600: tensor(6.3774, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 650\n",
            "Loss 650: tensor(6.2933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 700\n",
            "Loss 700: tensor(6.2494, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 750\n",
            "Loss 750: tensor(6.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 800\n",
            "Loss 800: tensor(6.2067, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 850\n",
            "Loss 850: tensor(6.1515, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 900\n",
            "Loss 900: tensor(6.0476, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 950\n",
            "Loss 950: tensor(6.0420, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 1000\n",
            "Loss 1000: tensor(6.0781, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 1050\n",
            "Loss 1050: tensor(6.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 1100\n",
            "Loss 1100: tensor(5.9493, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 1150\n",
            "Loss 1150: tensor(5.9862, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 1200\n",
            "Loss 1200: tensor(5.9517, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 1250\n",
            "Loss 1250: tensor(6.0321, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 1300\n",
            "Loss 1300: tensor(6.0041, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 1350\n",
            "Loss 1350: tensor(5.8626, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 1400\n",
            "Loss 1400: tensor(5.8338, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 1450\n",
            "Loss 1450: tensor(5.8013, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 1500\n",
            "Loss 1500: tensor(5.8664, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 1550\n",
            "Loss 1550: tensor(5.8862, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 1600\n",
            "Loss 1600: tensor(5.7554, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 1650\n",
            "Loss 1650: tensor(5.8739, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 1700\n",
            "Loss 1700: tensor(5.7984, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 1750\n",
            "Loss 1750: tensor(5.8645, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 1800\n",
            "Loss 1800: tensor(5.7206, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 1850\n",
            "Loss 1850: tensor(5.8316, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 1900\n",
            "Loss 1900: tensor(5.7006, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 1950\n",
            "Loss 1950: tensor(5.8845, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 2000\n",
            "Loss 2000: tensor(5.7612, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 2050\n",
            "Loss 2050: tensor(5.6704, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 2100\n",
            "Loss 2100: tensor(5.6684, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 2150\n",
            "Loss 2150: tensor(5.6316, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 2200\n",
            "Loss 2200: tensor(5.8310, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 2250\n",
            "Loss 2250: tensor(5.7422, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 2300\n",
            "Loss 2300: tensor(5.6471, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 2350\n",
            "Loss 2350: tensor(5.6904, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train completed: 2400\n",
            "Loss 2400: tensor(5.6409, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EQTK736JD9H8",
        "colab_type": "code",
        "outputId": "3b80e68f-63ee-48da-a8a9-023b3abaff9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "cell_type": "code",
      "source": [
        "net.eval()\n",
        "count = 0\n",
        "good = 0\n",
        "with torch.no_grad():\n",
        "  for user in seq_test:\n",
        "      inputs = torch.from_numpy(np.array(user[:-5],dtype=float)).long()\n",
        "      if use_cuda:\n",
        "          inputs = Variable(inputs.cuda())\n",
        "      labels = user[-5:]\n",
        "      inputs = inputs.view(1,inputs.size()[0])\n",
        "      outputs = net(inputs)\n",
        "      out = softmax(outputs[:,-1,:],dim=1).cpu().numpy().reshape(-1)\n",
        "      #print(outputs.min(),outputs.max(),outputs.sum())\n",
        "      #print(np.argmax(outputs))\n",
        "      top20 = np.argsort(out)[-20:]\n",
        "      okay = np.any([movie in labels for movie in top20])\n",
        "      if count%1000==0:\n",
        "        print(count)\n",
        "      count += 1\n",
        "      if okay:\n",
        "        good +=1\n",
        "print(good/count)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n",
            "0.5865451764158159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1J00S7CoVGhN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}